#version 430

layout (local_size_x = 320, local_size_y = 3) in;

// input: rendered and camera depth maps
layout (binding = 0) uniform sampler2D texCameraDepth;
layout (binding = 1) uniform sampler2D texRenderedDepth;

// work memory per 3*320 shader block
shared uint work_memory_d[320*3]; // difference
shared uint work_memory_u[320*3]; // union
shared uint work_memory_i[320*3]; // intersection

// output: per viewport per row reduction of diff/union/intersect in
// 3 pixels per row per viewport. layout
//
// d u i | ... | d u i      // 8 times
// .
// .                        // 240 * 8 times
// .
// d u i | ... | d u i
layout (binding = 0, r32ui) uniform restrict uimage2D imgResult;

layout (binding = 1, r32ui) uniform restrict uimage2D imgDifference;
layout (binding = 2, r8ui)  uniform restrict uimage2D imgUnion;
layout (binding = 3, r8ui)  uniform restrict uimage2D imgIntersection;

// maximum depth difference.  the range [znear, zfar] == [0.1, 1.1] is
// mapped to signed 16 bit depth values, i.e. 2^15 values. We want to
// clamp to 4cm, so dM = 2^15 * 0.04 ~= 1311. this means a 4cm spatial
// interval is still subdivided into 1311 values, so using 16 bit
// depth values for the clearly bounded interval seems sufficient and
// we still don't risk an overflow if all pixels contain the maximum
// depth difference: 320*240*1311 = 100684800 will fit nicely in a 32
// bit unsigned integer, as opposed to doing the same calculation for
// 24 bit depth values.
//uint dM = 1311;
float dM = 0.04; // screw this and use float in world frame

float zNear = 0.1;
float zFar  = 1.1;

// local thread id
uint lid = gl_LocalInvocationID.x +
	gl_WorkGroupSize.x * gl_LocalInvocationID.y;

float screen_to_world(float zScreen);
float half_screen_to_world(float zScreen);
uvec4 debug_color(uint val);

void main() {
	ivec2 posGlobal = ivec2(gl_GlobalInvocationID.xy);
	vec2  posScreen = vec2(posGlobal) / vec2(320*8, 240*8);

	float renderedSample = texture(texRenderedDepth, posScreen)[0];
	float cameraSample   = texture(texCameraDepth,   posScreen)[0];

	// camera samples are already in world space.
	// map rendered samples from screen to world space for depth
	// clamping in mm.
	renderedSample = half_screen_to_world(renderedSample);	

	uint inter_val =
		(renderedSample < 1.0f && cameraSample < 1.0f) ? 1 : 0;

	uint union_val =
		(renderedSample < 1.0f || cameraSample < 1.0f) ? 1 : 0;

	float clamped_difference;
	if(union_val > 0)
		clamped_difference = min( abs(cameraSample-renderedSample), dM);
	else
	 	clamped_difference = 0;

	// debug output image writes
	if(gl_GlobalInvocationID[0] < 320*1)
		imageStore(imgDifference,   posGlobal, uvec4(renderedSample*0xffffffffu, 0, 0, 0));
	else if(gl_GlobalInvocationID[0] < 320*2)
		imageStore(imgDifference,   posGlobal, uvec4(cameraSample*0xffffffffu, 0, 0, 0));
	else
		imageStore(imgDifference,   posGlobal, uvec4(clamped_difference/0.04f*0xffffffffu, 0, 0, 0));
	
	imageStore(imgUnion,        posGlobal, uvec4(union_val, 0, 0, 0));
	imageStore(imgIntersection, posGlobal, uvec4(inter_val, 0, 0, 0));
	
	// initialize work memory by texture lookup
	
	// union
	work_memory_u[lid] = union_val;

	// intersection
	work_memory_i[lid] = inter_val;

	// clamped difference
	work_memory_d[lid] = uint(clamped_difference * 0x7fffu);
	
	// make sure memory become visible to all instances
	barrier();

	// horizontal reduction loop
	for(uint stride = 1 ; stride < gl_WorkGroupSize.x ; stride *= 2) {
		if(gl_LocalInvocationID.x % (2*stride) == 0 &&
		   gl_LocalInvocationID.x + stride < gl_WorkGroupSize.x) {
			work_memory_d[lid] += work_memory_d[lid + stride];
			work_memory_u[lid] += work_memory_u[lid + stride];
			work_memory_i[lid] += work_memory_i[lid + stride];
		}
		barrier(); // sync writes to shared memory
	}

	// store shared memory to result texture
	if(gl_LocalInvocationID.x == 0) {
		ivec2 posResult = ivec2(gl_WorkGroupID.x * 3,
								gl_GlobalInvocationID.y);
		
		imageStore(imgResult, posResult + ivec2(0,0),
				   uvec4(work_memory_d[320*gl_LocalInvocationID.y], 0, 0, 0));
		imageStore(imgResult, posResult + ivec2(1,0),
				   uvec4(work_memory_u[320*gl_LocalInvocationID.y], 0, 0, 0));
		imageStore(imgResult, posResult + ivec2(2,0),
				   uvec4(work_memory_i[320*gl_LocalInvocationID.y], 0, 0, 0));
	}
}

float screen_to_world(float zScreen) {
	float zWorld = 2*zNear*zFar / (zFar + zNear - zScreen*(zFar - zNear));
	
	return zWorld;
}

float half_screen_to_world(float zScreen) {
	float zWorld = 2*zNear*zFar / (zFar + zNear - (zScreen*2.0f-1.0f) * (zFar - zNear));
	
	return zWorld;
}

uvec4 debug_color(uint val) {
	uvec4 color_out;
	
	if(gl_GlobalInvocationID[0] / 500 == 0) {
		color_out = uvec4((val & 0xff000000) >> 24,
						  0,
						  0,
						  0);
	}
	if(gl_GlobalInvocationID[0] / 500 == 1) {
		color_out = uvec4((val & 0x00ff0000) >> 16,
						  0,
						  0,
						  0);
	}
	if(gl_GlobalInvocationID[0] / 500 == 2) {
		color_out = uvec4((val & 0x0000ff00) >> 8,
						  0,
						  0,
						  0);
	}
	if(gl_GlobalInvocationID[0] / 500 == 3) {
		color_out = uvec4((val & 0x000000ff) >> 0,
						  0,
						  0,
						  0);
	}
	return color_out;
}
