#version 430

layout (local_size_x = 320, local_size_y = 3) in;

// input: rendered and camera depth maps
layout (binding = 0) uniform isampler2D texCameraDepth;
layout (binding = 1) uniform isampler2D texRenderedDepth;

// work memory per 3*320 shader block
shared uint work_memory_d[320*3]; // difference
shared uint work_memory_u[320*3]; // union
shared uint work_memory_i[320*3]; // intersection

// output: per viewport per row reduction of diff/union/intersect in
// 3 pixels per row per viewport. layout
//
// d u i | ... | d u i      // 8 times
// .
// .                        // 240 * 8 times
// .
// d u i | ... | d u i
layout (binding = 0, r32ui) uniform restrict uimage2D imgResult;
layout (binding = 1, r32ui) uniform restrict uimage2D imgDifference;
layout (binding = 2, r8ui)  uniform restrict uimage2D imgUnion;
layout (binding = 3, r8ui)  uniform restrict uimage2D imgIntersection;

// maximum depth difference.  the range [znear, zfar] == [0.1, 1.1] is
// mapped to signed 16 bit depth values, i.e. 2^15 values. We want to
// clamp to 4cm, so dM = 2^15 * 0.04 ~= 1311. this means a 4cm spatial
// interval is still subdivided into 1311 values, so using 16 bit
// depth values for the clearly bounded interval seems sufficient and
// we still don't risk an overflow if all pixels contain the maximum
// depth difference: 320*240*1311 = 100684800 will fit nicely in a 32
// bit unsigned integer, as opposed to doing the same calculation for
// 24 bit depth values.
uint dM = 1311;

// local thread id
uint lid = gl_LocalInvocationID.x +
	gl_WorkGroupSize.x * gl_LocalInvocationID.y;

void main() {
	ivec2 posGlobal = ivec2(gl_GlobalInvocationID.xy);
	vec2  posScreen = vec2(posGlobal) / vec2(320*8, 240*8);

	ivec4 renderedSample = texture(texRenderedDepth, posScreen);
	ivec4 cameraSample   = texture(texCameraDepth,   posScreen);

//	uint clamped_difference = min( abs(cameraSample[0]-renderedSample[0]), dM);
	uint clamped_difference = (cameraSample[0] & 0x007fffff);
		// abs((cameraSample[0]   & 0x00007fff) -
		// 	(renderedSample[0] & 0x00007fff));

	uint inter_val = 
		((renderedSample[0] & 0x00007fff) > 0) &&
		((cameraSample[0]   & 0x00007fff) > 0) ? 1 : 0;

	uint union_val =
		((renderedSample | cameraSample)[0] & 0x00007fff) > 0 ? 1 : 0;

	// debug output image writes
	imageStore(imgDifference,   posGlobal, uvec4(clamped_difference, 0, 0, 0));
	imageStore(imgUnion,        posGlobal, uvec4(union_val, 0, 0, 0));
	imageStore(imgIntersection, posGlobal, uvec4(inter_val, 0, 0, 0));
	
	// initialize work memory by texture lookup
	
	// union
	work_memory_u[lid] = union_val;

	// intersection
	work_memory_i[lid] = inter_val;

	// clamped difference
//	if(work_memory_u[lid] == 1)
	work_memory_d[lid] = clamped_difference;
	// else		
//	work_memory_d[lid] = 0xDA74; // 0xffffffff / 320 / 240

	// make sure memory become visible to all instances
	barrier();

	// horizontal reduction loop
	for(uint stride = 1 ; stride < gl_WorkGroupSize.x ; stride *= 2) {
		if(gl_LocalInvocationID.x % (2*stride) == 0 &&
		   gl_LocalInvocationID.x + stride < gl_WorkGroupSize.x) {
			work_memory_d[lid] += work_memory_d[lid + stride];
			work_memory_u[lid] += work_memory_u[lid + stride];
			work_memory_i[lid] += work_memory_i[lid + stride];
		}
		barrier(); // sync writes to shared memory
	}

	// store shared memory to result texture
	if(gl_LocalInvocationID.x == 0) {
		ivec2 posResult = ivec2(gl_WorkGroupID.x * 3,
								gl_GlobalInvocationID.y);
		
		imageStore(imgResult, posResult + ivec2(0,0),
				   uvec4(work_memory_d[320*gl_LocalInvocationID.y], 0, 0, 0));
		imageStore(imgResult, posResult + ivec2(1,0),
				   uvec4(work_memory_u[320*gl_LocalInvocationID.y], 0, 0, 0));
		imageStore(imgResult, posResult + ivec2(2,0),
				   uvec4(work_memory_i[320*gl_LocalInvocationID.y], 0, 0, 0));
	}
}
