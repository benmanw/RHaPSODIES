#version 430 core

layout (local_size_x = 3, local_size_y = 240) in;

// work memory per 240*3 shader block
shared uint work_memory[240*3];

// output: per-column reduced values
layout (binding = 0, r32ui) uniform restrict uimage2D imgResult;
layout (binding = 4, r32ui) uniform restrict uimage2D imgFinalResult;

// local thread id
uint lid = gl_LocalInvocationID.x +
	gl_WorkGroupSize.x * gl_LocalInvocationID.y;

void main() {
	ivec2 posGlobal = ivec2(gl_GlobalInvocationID.xy);

	// initialize work memory by texture lookup
	work_memory[lid] = imageLoad(imgResult, posGlobal)[0];

	// make sure memory become visible to all instances
	barrier();

	// vertical reduction loop
	for(uint stride = 1 ; stride < gl_WorkGroupSize.y ; stride *= 2) {
		if(gl_LocalInvocationID.y % (2*stride) == 0 &&
		   gl_LocalInvocationID.y + stride < gl_WorkGroupSize.y) {
			work_memory[lid] += work_memory[lid + stride*gl_WorkGroupSize.x];
		}
		barrier(); // sync writes to shared memory
	}

	// store shared memory to result texture
	if(gl_LocalInvocationID.y == 0) {
		imageStore(imgFinalResult,
				   ivec2(gl_WorkGroupID.x*3+gl_LocalInvocationID.x, gl_WorkGroupID.y),
				   uvec4(work_memory[gl_LocalInvocationID.x], 0, 0, 0));
	}
	// for now all store the result value for better visibility!
	// imageStore(imgResult, posGlobal,
	// 		   uvec4(work_memory[gl_LocalInvocationID.x], 0, 0, 0));
}
